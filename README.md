# üöÄ Data Stack: Airflow 2.10 ¬∑ Spark + Delta ¬∑ MinIO ¬∑ Metabase ¬∑ PostgreSQL

## üì¶ Servi√ßos & Portas

| Servi√ßo               | Porta(s)        | Usu√°rio / Senha padr√£o         |
|-----------------------|-----------------|--------------------------------|
| Airflow Webserver     | **8080**        | admin / admin123               |
| Airflow Flower        | **5555**        | ‚Äî                              |
| Spark Master UI       | **8081**        | ‚Äî                              |
| Spark Worker UI       | **8082**        | ‚Äî                              |
| Spark History Server  | **18080**       | ‚Äî                              |
| MinIO API             | **9000**        | minioadmin / minioadmin123     |
| MinIO Console         | **9001**        | minioadmin / minioadmin123     |
| Metabase              | **3000**        | (setup inicial via browser)    |
| PostgreSQL (Airflow)  | **5432**        | airflow / airflow_secret_2024  |
| PostgreSQL (Metabase) | **5433**        | metabase / metabase_secret_2024|
| Redis                 | **6379**        | ‚Äî                              |

---

## üõ†Ô∏è Setup r√°pido

### 1. Pr√©-requisitos
- Docker ‚â• 24 e Docker Compose v2
- ~8 GB RAM dispon√≠vel

### 2. Estrutura de diret√≥rios
```
.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env                        ‚Üê copie de .env.example
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ example_spark_delta_minio.py
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îî‚îÄ‚îÄ spark_delta_example.py
‚îú‚îÄ‚îÄ logs/
‚îú‚îÄ‚îÄ plugins/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ airflow.cfg             ‚Üê opcional
‚îî‚îÄ‚îÄ spark/
    ‚îú‚îÄ‚îÄ conf/
    ‚îÇ   ‚îî‚îÄ‚îÄ spark-defaults.conf
    ‚îî‚îÄ‚îÄ jars/                   ‚Üê coloque os JARs aqui (ver abaixo)
```

### 3. Configurar vari√°veis
```bash
cp .env.example .env
# Edite .env com suas senhas e gere a Fernet key:
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

### 4. Baixar JARs do Spark (Delta + S3A)
```bash
mkdir -p spark/jars
cd spark/jars

# Delta Lake 3.2.0 (compat√≠vel com Spark 3.5)
wget https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.2.0/delta-spark_2.12-3.2.0.jar
wget https://repo1.maven.org/maven2/io/delta/delta-storage/3.2.0/delta-storage-3.2.0.jar

# Hadoop AWS (S3A para MinIO)
wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar
wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar
```

### 5. Criar diret√≥rios necess√°rios
```bash
mkdir -p logs plugins config dags/scripts spark/conf spark/jars
echo -e "AIRFLOW_UID=$(id -u)" >> .env
```

### 6. Subir o stack
```bash
# Inicializa√ß√£o (primeira vez)
docker compose up airflow-init -d
docker compose logs -f airflow-init   # aguarde "Initialized successfully"

# Subir todos os servi√ßos
docker compose up -d

# Acompanhar logs
docker compose logs -f
```

### 7. Verificar sa√∫de dos servi√ßos
```bash
docker compose ps
```

---

## üîó Conex√£o Airflow ‚Üí Spark

No Airflow UI (`http://localhost:8080`), v√° em **Admin ‚Üí Connections** e crie:

| Campo       | Valor                          |
|-------------|--------------------------------|
| Conn Id     | `spark_default`                |
| Conn Type   | `Spark`                        |
| Host        | `spark://spark-master`         |
| Port        | `7077`                         |

---

## üîó Conectar Metabase ao PostgreSQL do Airflow

No setup inicial do Metabase (`http://localhost:3000`):
- **Host:** `postgres-airflow`
- **Port:** `5432`
- **Database:** `airflow`
- **User/Pass:** conforme `.env`

> ‚ö†Ô∏è Use o hostname `postgres-airflow` (nome do servi√ßo Docker) ‚Äî n√£o `localhost`.

---

## üóÇÔ∏è Buckets MinIO criados automaticamente

| Bucket        | Uso                          |
|---------------|------------------------------|
| `delta-lake`  | Tabelas Delta Lake           |
| `spark-logs`  | Logs de eventos do Spark     |
| `airflow-logs`| Logs do Airflow              |

---

## üîÑ Comandos √∫teis

```bash
# Parar tudo
docker compose down

# Parar e apagar volumes (‚ö†Ô∏è destr√≥i dados)
docker compose down -v

# Reiniciar s√≥ o Airflow Scheduler
docker compose restart airflow-scheduler

# Escalar workers
docker compose up --scale airflow-worker=3 -d

# Ver logs de um servi√ßo espec√≠fico
docker compose logs -f spark-master
```

---

## ‚ö†Ô∏è Resolu√ß√£o de conflitos de porta

Se alguma porta j√° estiver em uso na sua m√°quina, edite o `docker-compose.yml`:

```yaml
# Exemplo: mudar Airflow de 8080 para 8090
ports:
  - "8090:8080"   # host:container
```

| Conflito comum          | Causa                          | Solu√ß√£o sugerida         |
|-------------------------|--------------------------------|--------------------------|
| 5432 ocupada            | PostgreSQL local               | Mudar host para `5434`   |
| 8080 ocupada            | Outro servidor web             | Mudar para `8090`        |
| 9000 ocupada            | Outro S3/objeto store          | Mudar para `9002`        |
| 3000 ocupada            | Grafana ou outro app           | Mudar para `3001`        |
